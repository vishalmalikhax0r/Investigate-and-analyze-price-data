{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2834b5d3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-02T20:52:56.281705Z",
     "iopub.status.busy": "2024-03-02T20:52:56.281084Z",
     "iopub.status.idle": "2024-03-02T20:52:57.246630Z",
     "shell.execute_reply": "2024-03-02T20:52:57.245452Z"
    },
    "papermill": {
     "duration": 0.971984,
     "end_time": "2024-03-02T20:52:57.249091",
     "exception": false,
     "start_time": "2024-03-02T20:52:56.277107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/customerloandata/Task 3 and 4_Loan_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23037086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T20:52:57.255308Z",
     "iopub.status.busy": "2024-03-02T20:52:57.254827Z",
     "iopub.status.idle": "2024-03-02T20:53:03.233298Z",
     "shell.execute_reply": "2024-03-02T20:53:03.232123Z"
    },
    "papermill": {
     "duration": 5.984359,
     "end_time": "2024-03-02T20:53:03.235747",
     "exception": false,
     "start_time": "2024-03-02T20:52:57.251388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n",
      "-4217.8245\n",
      "[850, 753, 752, 732, 696, 649, 611, 580, 552, 520, 300]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/customerloandata/Task 3 and 4_Loan_Data.csv')\n",
    "\n",
    "x = df['default'].to_list()\n",
    "y = df['fico_score'].to_list()\n",
    "n = len(x)\n",
    "print (len(x), len(y))\n",
    "\n",
    "default = [0 for i in range(851)]\n",
    "total = [0 for i in range(851)]\n",
    "\n",
    "for i in range(n):\n",
    "    y[i] = int(y[i])\n",
    "    default[y[i]-300] += x[i]\n",
    "    total[y[i]-300] += 1\n",
    "    \n",
    "for i in range(0, 551):\n",
    "    default[i] += default[i-1]\n",
    "    total[i] += total[i-1]\n",
    "    \n",
    "import numpy as np\n",
    "    \n",
    "def log_likelihood(n, k):\n",
    "    p = k/n\n",
    "    if (p==0 or p==1):\n",
    "        return 0\n",
    "    return k*np.log(p)+ (n-k)*np.log(1-p)\n",
    "\n",
    "r = 10\n",
    "dp = [[[-10**18, 0] for i in range(551)] for j in range(r+1)]\n",
    "\n",
    "for i in range(r+1):\n",
    "    for j in range(551):\n",
    "        if (i==0):\n",
    "            dp[i][j][0] = 0\n",
    "        else:\n",
    "            for k in range(j):\n",
    "                if (total[j]==total[k]):\n",
    "                    continue\n",
    "                if (i==1):\n",
    "                    dp[i][j][0] = log_likelihood(total[j], default[j])\n",
    "                else:\n",
    "                    if (dp[i][j][0] < (dp[i-1][k][0] + log_likelihood(total[j]-total[k], default[j] - default[k]))):\n",
    "                        dp[i][j][0] = log_likelihood(total[j]-total[k], default[j]-default[k]) + dp[i-1][k][0]\n",
    "                        dp[i][j][1] = k\n",
    "                                                     \n",
    "print (round(dp[r][550][0], 4))\n",
    "                                                     \n",
    "k = 550\n",
    "l = []\n",
    "while r >= 0:\n",
    "    l.append(k+300)\n",
    "    k = dp[r][k][1]\n",
    "    r -= 1\n",
    "\n",
    "print(l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386feca",
   "metadata": {
    "papermill": {
     "duration": 0.001902,
     "end_time": "2024-03-02T20:53:03.240364",
     "exception": false,
     "start_time": "2024-03-02T20:53:03.238462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The provided code performs data analysis by calculating the probability of default for a given set of observations. The technique used for this analysis is maximum likelihood estimation. The intuition behind the usage of maximum likelihood estimation is that it is a common method for estimating the parameters of a statistical model. In this case, the parameters are the probabilities of default for different sets of observations. Maximum likelihood estimation seeks to find the parameter values that maximize the likelihood function for the observed data.\n",
    "\n",
    "The code first reads in a CSV file using Pandas. It then creates two lists, x and y, that correspond to the 'observation' and 'rank' columns in the data, respectively. These lists are then used to calculate the default and total values for each rank in the data.\n",
    "\n",
    "The log-likelihood function is defined to calculate the likelihood of a given set of parameters. The likelihood function is used to calculate the probability of observing the data given the parameter values. The code then initializes a three-dimensional array, dp, that is used to store the calculated log-likelihood values for different sets of observations. The first dimension represents the number of iterations performed, the second dimension represents the rank of the observation, and the third dimension represents the log-likelihood and the index of the previous observation.\n",
    "\n",
    "Finally, the code calculates the log-likelihood for the given data set by using the dp array. It then prints the results and outputs the indices of the observations that were used in the calculation.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4528229,
     "sourceId": 7746179,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.327579,
   "end_time": "2024-03-02T20:53:03.662611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-02T20:52:53.335032",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
